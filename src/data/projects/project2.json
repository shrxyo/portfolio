{
  "mainHeading": "Text augmentation using LLMs in Medical Transcripts.",
  "dates": "September 2024 - December 2024",
  "technologies": [ "Python", "Prompt Engineering", "OpenAI API", "ClinicalBERT", "ALBERT", "T5", "CNN", "BiLSTM" ],
  "context": "Research project focused on solving extreme class imbalance in medical transcription datasets using LLM-based text generation and comparative evaluation against SMOTE.",
  "objectives": [
    "Generated 800+ synthetic samples using ClinicalBERT, ALBERT, GPT-Neo, and T5 to balance minority classes.",
    "Increased minority class representation by an average of 200.45% across all categories.",
    "Benchmarked performance using CNN and CNN+BiLSTM classifiers trained on augmented datasets.",
    "Compared LLM-based augmentation with SMOTE (which only achieved 53% accuracy).",
    "Demonstrated superior accuracy, precision, recall, and F1-score with LLM-generated data."
  ],
  "features": [
    "Used ClinicalBERT and ALBERT for domain-specific augmentation.",
    "Generated paraphrased and diverse examples using GPT-Neo and T5.",
    "Achieved 94.3% accuracy with ALBERT, 91.9% with ClinicalBERT on CNN+BiLSTM models.",
    "Outperformed traditional SMOTE baseline significantly across all metrics.",
    "Applied LLM evaluation metrics and fine-tuned prompts for better data diversity."
  ],
  "liveLink": "https://drive.google.com/file/d/1IziQ74_yzfVqkXb4XnAp94QCOeKvhXHF/view?usp=sharing"
} 